{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitzanEz/Final-Project/blob/main/classificationCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Pze-76cY2Q"
      },
      "source": [
        "Cloning the project repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTbd9pey_aqf",
        "outputId": "c695ecbe-ecdc-4cbc-d794-35ef3b0ddc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Final-Project'...\n",
            "remote: Enumerating objects: 112825, done.\u001b[K\n",
            "remote: Counting objects: 100% (434/434), done.\u001b[K\n",
            "remote: Compressing objects: 100% (429/429), done.\u001b[K\n",
            "remote: Total 112825 (delta 34), reused 5 (delta 5), pack-reused 112391 (from 9)\u001b[K\n",
            "Receiving objects: 100% (112825/112825), 2.39 GiB | 23.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1481/1481), done.\n",
            "Updating files: 100% (61832/61832), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NitzanEz/Final-Project.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2N3K5PZuCXk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwdxv6Dcp7r"
      },
      "source": [
        "Import necessary libraries and define preprocessing and convolutional operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVhQ89EkWAcd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7VGuYDNao_5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization, concatenate\n",
        "from tensorflow.keras import regularizers, initializers, Model\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Normalization\n",
        "\n",
        "\n",
        "#########################################################################################\n",
        "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
        "#########################################################################################\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def preprocess_input(x):\n",
        "\n",
        "    x = np.divide(x, 255.0)\n",
        "    x = np.subtract(x, 0.5)\n",
        "    x = np.multiply(x, 2.0)\n",
        "    return x\n",
        "\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col, padding='same', strides=(1, 1), use_bias=False):\n",
        "    \"\"\"\n",
        "    Utility function to apply conv + BN.\n",
        "    \"\"\"\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "    x = Conv2D(nb_filter, (num_row, num_col),\n",
        "               strides=strides,\n",
        "               padding=padding,\n",
        "               use_bias=use_bias,\n",
        "               kernel_regularizer=regularizers.l2(0.00004),\n",
        "               kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def block_inception_a(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_reduction_a(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_inception_b(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_reduction_b(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_inception_c(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
        "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
        "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
        "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
        "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
        "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def inception_v4_base(input):\n",
        "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    norm_layer = Normalization(axis=-1)\n",
        "\n",
        "    # Apply normalization to the input tensor\n",
        "    x = norm_layer(input)\n",
        "\n",
        "    # Proceed with the model architecture\n",
        "    x = conv2d_bn(x, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    x = conv2d_bn(x, 32, 3, 3, strides=(2, 2), padding='valid')\n",
        "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "    net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
        "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    # 4 x Inception-A blocks\n",
        "    for i in range(4):\n",
        "        net = block_inception_a(net)\n",
        "\n",
        "    # Reduction-A block\n",
        "    net = block_reduction_a(net)\n",
        "\n",
        "    # 7 x Inception-B blocks\n",
        "    for i in range(7):\n",
        "        net = block_inception_b(net)\n",
        "\n",
        "    # Reduction-B block\n",
        "    net = block_reduction_b(net)\n",
        "\n",
        "    # 3 x Inception-C blocks\n",
        "    for i in range(3):\n",
        "        net = block_inception_c(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
        "    inputs = Input((299, 299, 3))\n",
        "    x = inception_v4_base(inputs)\n",
        "\n",
        "    if include_top:\n",
        "        x = AveragePooling2D((8, 8), padding='valid')(x)\n",
        "        x = Dropout(dropout_keep_prob)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x, name='inception_v4')\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('inception-v4_weights_tf_dim_ordering_tf_kernels.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "        else:\n",
        "            weights_path = get_file('inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "    return model\n",
        "\n",
        "def create_and_compile_model(num_classes=1001, dropout_prob=0.3, weights='imagenet', include_top=True, learning_rate=0.0001):\n",
        "    model = inception_v4(num_classes, dropout_prob, weights, include_top)\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Usage\n",
        "model = create_and_compile_model(num_classes=1001, dropout_prob=0.3, weights='imagenet', include_top=True, learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtI3ZFnDcwSK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "kHBFsHdDKEcf",
        "outputId": "49cb6c06-d8b6-48ad-f884-b06527ab162a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inception_v4_base' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb7b23e27285>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Input layer definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbase_model_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_v4_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inception_v4_base' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Input layer definition\n",
        "inputs = Input(shape=(299, 299, 3))\n",
        "base_model_output = inception_v4_base(inputs)\n",
        "x = GlobalAveragePooling2D()(base_model_output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Model setup\n",
        "model = Model(inputs, predictions)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Directory paths for train, validation, and test datasets\n",
        "train_dir = '/content/Final-Project/Data/train'\n",
        "validation_dir = '/content/Final-Project/Data/validation'\n",
        "test_dir = '/content/Final-Project/Data/test'\n",
        "\n",
        "# Image data generator for training with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Image data generator for validation and testing (no data augmentation)\n",
        "test_val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Data generators for train, validation, and test sets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('final_model.keras')\n",
        "\n",
        "# Optionally load and use the model\n",
        "final_model = load_model('final_model.keras')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = final_model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_accuracy}, Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "YA34yoCP-WqB",
        "outputId": "bf6b3cf9-d688-43a7-ae9d-5f4899b8cc2e"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File not found: filepath=/content/best_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-756c580a4bda>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load your Inception v4 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/best_model.keras'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Correct path to your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n\u001b[1;32m    197\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/content/best_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "\n",
        "# Load your Inception v4 model\n",
        "model = load_model('/content/best_model.keras')  # Correct path to your model\n",
        "\n",
        "def preprocess_input(x):\n",
        "    \"\"\"Preprocess the input image for Inception v4.\"\"\"\n",
        "    x = np.divide(x, 255.0)  # Normalize to [0, 1]\n",
        "    x = np.subtract(x, 0.5)  # Center to [-0.5, 0.5]\n",
        "    x = np.multiply(x, 2.0)  # Scale to [-1, 1]\n",
        "    return x\n",
        "\n",
        "def load_and_pad_image(file_path, target_size=(299, 299)):\n",
        "    \"\"\"Load an image and pad it to the target size.\"\"\"\n",
        "    img = keras_image.load_img(file_path)\n",
        "    img = img.resize(target_size, Image.Resampling.LANCZOS)  # Use LANCZOS for high-quality downsampling\n",
        "    img_array = keras_image.img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)  # Custom preprocessing for Inception v4\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Path to your image\n",
        "image_path = '/content/Final-Project/Data/test/ASD/28872/slice_136.jpg'  # Correct path to your image\n",
        "\n",
        "# Load and pad the image\n",
        "prepared_image = load_and_pad_image(image_path)\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(prepared_image)\n",
        "predicted_class = np.argmax(predictions, axis=1)  # Assuming your model outputs logits for each class\n",
        "\n",
        "# Map the class indices back to class labels if necessary\n",
        "class_labels = {0: 'Non-ASD', 1: 'ASD'}\n",
        "predicted_label = class_labels[predicted_class[0]]\n",
        "\n",
        "print(f\"The image is classified as: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo8GtYkeVCvg"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Try to open an image file directly with PIL\n",
        "try:\n",
        "    img = Image.open('path_to_problematic_image.jpg')\n",
        "    img.show()  # This will display the image if it can be opened\n",
        "except IOError:\n",
        "    print(\"Cannot open image\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmPkH9q26phl"
      },
      "outputs": [],
      "source": [
        "!git add classificationCode.ipynb  # Change 'Notebook.ipynb' to your file name\n",
        "!git commit -m \"Add Jupyter notebook\"\n",
        "!git push\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}