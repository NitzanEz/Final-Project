{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitzanEz/Final-Project/blob/main/classificationCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTbd9pey_aqf",
        "outputId": "df89eac1-daed-4496-e872-5a04339ec0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Final-Project'...\n",
            "remote: Enumerating objects: 89069, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 89069 (delta 9), reused 18 (delta 7), pack-reused 89044 (from 1)\u001b[K\n",
            "Receiving objects: 100% (89069/89069), 1.08 GiB | 23.95 MiB/s, done.\n",
            "Resolving deltas: 100% (1350/1350), done.\n",
            "Updating files: 100% (114786/114786), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NitzanEz/Final-Project.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d7VGuYDNao_5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization, concatenate\n",
        "from tensorflow.keras import regularizers, initializers, Model\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "#########################################################################################\n",
        "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
        "#########################################################################################\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x = np.divide(x, 255.0)\n",
        "    x = np.subtract(x, 0.5)\n",
        "    x = np.multiply(x, 2.0)\n",
        "    return x\n",
        "\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col, padding='same', strides=(1, 1), use_bias=False):\n",
        "    \"\"\"\n",
        "    Utility function to apply conv + BN.\n",
        "    \"\"\"\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "    x = Conv2D(nb_filter, (num_row, num_col),\n",
        "               strides=strides,\n",
        "               padding=padding,\n",
        "               use_bias=use_bias,\n",
        "               kernel_regularizer=regularizers.l2(0.00004),\n",
        "               kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def block_inception_a(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_reduction_a(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_inception_b(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_reduction_b(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def block_inception_c(input):\n",
        "    channel_axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
        "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
        "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
        "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
        "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
        "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "def inception_v4_base(input):\n",
        "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "    net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
        "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    # 4 x Inception-A blocks\n",
        "    for i in range(4):\n",
        "        net = block_inception_a(net)\n",
        "\n",
        "    # Reduction-A block\n",
        "    net = block_reduction_a(net)\n",
        "\n",
        "    # 7 x Inception-B blocks\n",
        "    for i in range(7):\n",
        "        net = block_inception_b(net)\n",
        "\n",
        "    # Reduction-B block\n",
        "    net = block_reduction_b(net)\n",
        "\n",
        "    # 3 x Inception-C blocks\n",
        "    for i in range(3):\n",
        "        net = block_inception_c(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
        "    inputs = Input((299, 299, 3))\n",
        "    x = inception_v4_base(inputs)\n",
        "\n",
        "    if include_top:\n",
        "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
        "        x = Dropout(dropout_keep_prob)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x, name='inception_v4')\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('inception-v4_weights_tf_dim_ordering_tf_kernels.h5', WEIGHTS_PATH, cache_subdir='models', md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
        "        else:\n",
        "            weights_path = get_file('inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', md5_hash='9296b46b5971573064d12e4669110969')\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "    return model\n",
        "\n",
        "def create_model(num_classes=1001, dropout_prob=0.2, weights='imagenet', include_top=True):\n",
        "    return inception_v4(num_classes, dropout_prob, weights, include_top)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iwgS8eAq-HiT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def preprocess_mri_image(image_path):\n",
        "    img = load_img(image_path, color_mode='grayscale', target_size=(299, 299))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.repeat(img_array, 3, axis=2)  # Repeat the grayscale data across three channels\n",
        "    img_array = preprocess_input(img_array)  # Normalize using the provided function\n",
        "    return img_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kHBFsHdDKEcf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Assuming you have a base model setup already (e.g., InceptionV4)\n",
        "inputs = Input(shape=(299, 299, 3))\n",
        "base_model_output = inception_v4_base(inputs)  # Make sure this function is adjusted or correctly implemented\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model_output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)  # Change this to 2 classes\n",
        "\n",
        "model = Model(inputs, predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jGNGLAQdEY0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa33280-8c16-46da-c983-aea3a859d23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 76760 images belonging to 2 classes.\n",
            "Found 21972 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define the paths to the training and validation directories\n",
        "train_dir = '/content/Final-Project/Data/train'\n",
        "validation_dir = '/content/Final-Project/Data/validation'\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up the image data generators with preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input  # Make sure this function is defined or imported\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Setup for validation data generator\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFZFxLShCxuZ",
        "outputId": "3dee5633-422c-4347-aaef-be1fa4ad93b8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 11/100\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42:55\u001b[0m 69s/step - accuracy: 0.4870 - loss: 4.3446"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA34yoCP-WqB"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# Assume 'test_generator' is set up similarly to 'train_generator'\n",
        "evaluation = model.evaluate(test_generator)\n",
        "\n",
        "# Making predictions\n",
        "image_path = '/content/Final-Project/Data/train/ASD/28764/slice_242.jpg'\n",
        "processed_image = preprocess_mri_image(image_path)\n",
        "processed_image = np.expand_dims(processed_image, axis=0)  # Add batch dimension for prediction\n",
        "prediction = model.predict(processed_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmPkH9q26phl"
      },
      "outputs": [],
      "source": [
        "!git add classificationCode.ipynb  # Change 'Notebook.ipynb' to your file name\n",
        "!git commit -m \"Add Jupyter notebook\"\n",
        "!git push\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP81rkp/ZaWonTuilazWZ0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}